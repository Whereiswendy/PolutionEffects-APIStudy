{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API Data Extraction Process and Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Exploring processes and code to easily access data relevant to study/project.\n",
    "\n",
    "### Project Hypothesis:\n",
    "Socioeconomic status, as indicated by income levels, education attainment, and race/ethnicity, is a significant predictor of air quality and health outcomes. Communities with lower socioeconomic status are hypothesized to experience poorer air quality, which in turn leads to a higher prevalence of adverse health outcomes. This relationship is expected to persist even when controlling for potential confounding variables such as geographic location and access to healthcare services.\n",
    "\n",
    "### Defining Data Collection Parameters\n",
    "- **Geographic Scope:** Define countries or cities of interest\n",
    "- **Time Frame:** Define time period coverage\n",
    "- **Socioeconomic Indicators:** Define indicators of interest (e.g., median income, education level)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "\n",
    "# Import the relevant API keys ( you will need )\n",
    "from api_keys import weather_api_key\n",
    "from api_keys import geoapify_key\n",
    "from api_keys import aqicn_api_key\n",
    "from api_keys import gho_who_api_key\n",
    "from api_keys import api_ninjas_key\n",
    "\n",
    "# Import citipy to determine the cities based on latitude and longitude\n",
    "from citipy import citipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Geographic scope\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique cities in the list: 618\n"
     ]
    }
   ],
   "source": [
    "# Empty list for holding the latitude and longitude combinations\n",
    "lat_lngs = []\n",
    "\n",
    "# Empty dictionary for holding the city names and country codes\n",
    "city_details = {}\n",
    "\n",
    "# Range of latitudes and longitudes\n",
    "lat_range = (-90, 90) # Min and Max bounds for latitude range\n",
    "lng_range = (-180, 180) # Min and Max bounds for longitude range\n",
    "\n",
    "# Create a set of random lat and lng combinations\n",
    "lats = np.random.uniform(lat_range[0], lat_range[1], size=1500)\n",
    "lngs = np.random.uniform(lng_range[0], lng_range[1], size=1500)\n",
    "lat_lngs = zip(lats, lngs) # Aggregate into tuple - pairing latitudes and longitudes\n",
    "\n",
    "# Identify nearest city, country, and record their coordinates for each lat, lng combination\n",
    "for lat, lng in lat_lngs:\n",
    "    city = citipy.nearest_city(lat, lng)\n",
    "    city_name = city.city_name\n",
    "    country_code = city.country_code\n",
    "    coords = (lat, lng)\n",
    "    \n",
    "    # If the city is unique, then add it along with the country code and coordinates\n",
    "    if city_name not in city_details:\n",
    "        city_details[city_name] = (country_code, coords)\n",
    "\n",
    "# Print the city count to confirm sufficient count\n",
    "print(f\"Number of unique cities in the list: {len(city_details)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Index                         City Country  \\\n",
      "0        0                      malpica      es   \n",
      "1        1                       bethel      us   \n",
      "2        2               ribeira grande      pt   \n",
      "3        3  edinburgh of the seven seas      sh   \n",
      "4        4                       albany      au   \n",
      "..     ...                          ...     ...   \n",
      "613    613                       murzuq      ly   \n",
      "614    614             charlotte amalie      vi   \n",
      "615    615                     kangding      cn   \n",
      "616    616                    dingcheng      cn   \n",
      "617    617                    groningen      sr   \n",
      "\n",
      "                                        Coords  \n",
      "0     (46.058636950605745, -9.777245982901945)  \n",
      "1      (68.68194407511422, -164.0566600183777)  \n",
      "2      (48.51075858434373, -32.88817223429896)  \n",
      "3     (-37.98593329638902, -1.392334171241373)  \n",
      "4    (-58.607549635501265, 124.70233480599364)  \n",
      "..                                         ...  \n",
      "613    (23.98361572585003, 13.641477037660138)  \n",
      "614    (18.714373021089727, -65.0067445411061)  \n",
      "615   (32.785853194924485, 101.23845273354056)  \n",
      "616   (32.385756595195446, 115.15736770440822)  \n",
      "617    (5.575780986260668, -55.89521675244734)  \n",
      "\n",
      "[618 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame from the collected data\n",
    "cities_selected_df = pd.DataFrame({\n",
    "    'City': [k for k in city_details.keys()],\n",
    "    'Country': [v[0] for v in city_details.values()],\n",
    "    'Coords': [v[1] for v in city_details.values()]\n",
    "})\n",
    "\n",
    "# Reset index to make sure it starts from 0 and acts as an index column\n",
    "cities_selected_df.reset_index(inplace=True)\n",
    "cities_selected_df.rename(columns={'index': 'Index'}, inplace=True)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(cities_selected_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Socio-economic indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AQICN API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Replace with your actual API key\n",
    "# api_key = 'YOUR_AQICN_API_KEY'\n",
    "\n",
    "# # Define the endpoint and parameters for your request\n",
    "# endpoint = 'http://api.waqi.info/feed/'\n",
    "# city = 'city_name'\n",
    "# params = {\n",
    "#     'token': api_key\n",
    "# }\n",
    "\n",
    "# # Make the request and collect the data\n",
    "# response = requests.get(f'{endpoint}/{city}/', params=params)\n",
    "# data = response.json()\n",
    "\n",
    "# # Extract data and convert to DataFrame\n",
    "# aq_data = data['data']['iaqi']\n",
    "# df_aq = pd.DataFrame(aq_data).transpose()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API Ninja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: this is the code used - it uses about 5% of the month allocation of 10000 requests. One can batch into groups of 30 to reduce the number of requests.\n",
    "\n",
    "cities_selected_df1=cities_selected_df.copy()\n",
    "\n",
    "headers = {'X-Api-Key': api_ninjas_key}\n",
    "\n",
    "# Empty list to store the results\n",
    "results = []\n",
    "\n",
    "# Function to fetch data for a city\n",
    "def get_city_data(city):\n",
    "    url = f'https://api.api-ninjas.com/v1/city?name={city}'\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data for {city}, status code {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Loop through the DataFrame and call the API for each city\n",
    "for row in cities_selected_df1.itertuples():\n",
    "    # Convert city names to Title Case\n",
    "    city_name_formatted = row.City.title()  # Corrected to use 'City' instead of 'city_name'\n",
    "    data = get_city_data(city_name_formatted)\n",
    "    if data:\n",
    "        results.extend(data)  # Extend in case data is a list of multiple cities\n",
    "    # Implement a delay between API calls to avoid hitting the rate limit\n",
    "    time.sleep(1)\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "df_cities_results = pd.DataFrame(results)\n",
    "\n",
    "# Create the directory if it does not exist\n",
    "if not os.path.exists('Data'):\n",
    "    os.makedirs('Data')\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df_cities_results.to_csv(\"Data/city_data_ww.csv\", index =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a is_rural variable to the dataframe\n",
    "\n",
    "# 1. Make a copy of the DataFrame\n",
    "df_cities_results1 = df_cities_results.copy()\n",
    "\n",
    "# 2. Generate a column called is_rural\n",
    "# Assuming the population column is named \"Population\"\n",
    "df_cities_results1['is_rural'] = df_cities_results1['population'] < 15000  # This will return True for rural and False for urban\n",
    "\n",
    "# 3. Loop through the populations against measures\n",
    "# This step is not needed as the vectorized operation above handles the classification based on population\n",
    "\n",
    "# 4. Output to \"Data/city_data.csv\"\n",
    "df_cities_results1.to_csv(\"Data/city_data1_ww.csv\", index=False)  # index=False to avoid writing row indices in the CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
